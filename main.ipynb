{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a0784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13da22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available()\n",
    "          else \"mps\" if torch.backends.mps.is_available()\n",
    "          else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "c8a8ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training data size: {len(os.listdir('./images_thermal_train/data'))} images\")\n",
    "print(f\"Testing data size: {len(os.listdir('./images_thermal_val/data'))} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> temp
   "id": "fab0013f",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "END = 30 # How many images to process, set to None to process all images\n",
=======
    "END = None # How many images to process, set to None to process all images\n",
>>>>>>> temp
    "\n",
    "# -- Create the file structure\n",
    "def make_file_structure():\n",
    "    base_dir = \".\"\n",
    "    dirs = [\"images/train\", \"images/val\", \"labels/train\", \"labels/val\"]\n",
    "\n",
    "    for d in dirs:\n",
    "        os.makedirs(os.path.join(base_dir, d), exist_ok=True)\n",
    "\n",
    "# -- Add data to images folder\n",
    "def add_images_to_file(src, dest, start=0, end=None, train=True):\n",
    "    src_path = os.path.join(src, \"data\")\n",
    "\n",
    "    if train:\n",
    "        dest_path = os.path.join(dest, \"train\")\n",
    "    else:\n",
    "        dest_path = os.path.join(dest, \"val\")\n",
    "\n",
    "    # -- Remove existing folder from previous run and make a new one\n",
    "    if os.path.exists(dest_path):\n",
    "        shutil.rmtree(dest_path)\n",
    "    os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "    # Collecting all the image files\n",
    "    files = [f for f in os.listdir(src_path) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "    files = sorted(files)\n",
    "    \n",
    "    # If end is None, process all files\n",
    "    if end is None:\n",
    "        end = len(files)\n",
    "    \n",
    "    files = files[start:end]\n",
    "\n",
    "    # -- Copying the selected files\n",
    "    for file in files:\n",
    "        shutil.copy(os.path.join(src_path, file), os.path.join(dest_path, file))\n",
    "    \n",
    "    print(f\"Copied {len(files)} images to {dest_path}\")\n",
    "    return files \n",
    "\n",
    "# -- Adding labels to label folder\n",
    "def add_labels_to_file(src, dest, image_files=None, train=True):\n",
    "    json_file = os.path.join(src, \"coco.json\")\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    annotations = data[\"annotations\"]\n",
    "    images = {img[\"id\"]: img for img in data[\"images\"]}\n",
    "\n",
    "    # Create a mapping from category_id to index\n",
    "    '''categories = {cat[\"id\"]: idx for idx, cat in enumerate(data[\"categories\"])}'''\n",
    "    \n",
    "    # Checnking config files for matching labels\n",
    "    #----------------------------------------------------------------------    \n",
    "    with open(\"config.yml\", \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    names = [n.lower().strip() for n in cfg[\"names\"]]\n",
    "    name_to_idx = {n: i for i, n in enumerate(names)}\n",
    "\n",
    "    # Build mapping by name\n",
    "    catid_to_idx = {}\n",
    "    for cat in data[\"categories\"]:\n",
    "        cname = cat[\"name\"].lower().strip()\n",
    "        if cname in name_to_idx:\n",
    "            catid_to_idx[cat[\"id\"]] = name_to_idx[cname]\n",
    "        else:\n",
    "            print(f\"Skipping unmatched category: {cname}\")\n",
    "    #----------------------------------------------------------------------\n",
    "\n",
    "    # Create destination directory if it doesn't exist\n",
    "    label_dir = os.path.join(dest, \"train\" if train else \"val\")\n",
    "    if os.path.exists(label_dir):\n",
    "        shutil.rmtree(label_dir)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    \n",
    "    # If image_files is provided, filter to only those images\n",
    "    if image_files is not None:\n",
    "        image_filenames = set(image_files)\n",
    "        # Filter images dict to only include the specified files\n",
    "        images = {img_id: img_info for img_id, img_info in images.items() \n",
    "                  if os.path.basename(img_info[\"file_name\"]) in image_filenames}\n",
    "    \n",
    "    # Group annotations by image_id (only for filtered images)\n",
    "    img_anno = {}\n",
    "    for anno in annotations:\n",
    "        img_id = anno[\"image_id\"]\n",
    "        if img_id in images:\n",
    "            if img_id not in img_anno:\n",
    "                img_anno[img_id] = []\n",
    "            img_anno[img_id].append(anno)\n",
    "    \n",
    "    # Process each image\n",
    "    processed = 0\n",
    "    for img_id, annos in img_anno.items():\n",
    "        img_info = images[img_id]\n",
    "        img_width = img_info[\"width\"]\n",
    "        img_height = img_info[\"height\"]\n",
    "        img_filename = img_info[\"file_name\"]\n",
    "\n",
    "        # Extract just the filename\n",
    "        base_filename = os.path.basename(img_filename)\n",
    "        \n",
    "        # Create label files\n",
    "        label_filename = os.path.splitext(base_filename)[0] + \".txt\"\n",
    "        label_path = os.path.join(dest, \"train\" if train else \"val\", label_filename)\n",
    "\n",
    "        # Write in YOLO format\n",
    "        with open(label_path, \"w\") as l:\n",
    "            for anno in annos:\n",
    "                category_id = anno[\"category_id\"]\n",
    "                \n",
    "                if category_id not in catid_to_idx:\n",
    "                    print(f\"Warning: Category {category_id} not found\")\n",
    "                    continue\n",
    "                    \n",
    "                class_idx = catid_to_idx[category_id]\n",
    "\n",
    "                bbox = anno[\"bbox\"]\n",
    "\n",
    "                x, y, w, h = bbox\n",
    "                x_center = (x + w / 2) / img_width\n",
    "                y_center = (y + h / 2) / img_height\n",
    "                w_norm = w / img_width\n",
    "                h_norm = h / img_height\n",
    "\n",
    "                l.write(f\"{class_idx} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "        \n",
    "        processed += 1\n",
    "    \n",
    "    print(f\"Processed {processed} label files in {label_dir}\")\n",
    "\n",
    "\n",
    "make_file_structure()\n",
    "\n",
    "train_files = add_images_to_file(\"./images_thermal_train\", \"./images\", start=0, end=END, train=True)\n",
    "add_labels_to_file(\"./images_thermal_train\", \"./labels\", image_files=train_files, train=True)\n",
    "\n",
    "val_files = add_images_to_file(\"./images_thermal_val\", \"./images\", start=0, end=END, train=False)\n",
    "add_labels_to_file(\"./images_thermal_val\", \"./labels\", image_files=val_files, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca001f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Visualizing the first image and annotations\n",
    "import cv2\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yml\", \"r\") as f:\n",
    "    data_yaml = yaml.safe_load(f)\n",
    "class_names = data_yaml[\"names\"]\n",
    "\n",
    "#Sort files to ensure matching images and files\n",
    "img_files = sorted(os.listdir('./images/train'))\n",
    "label_files = sorted(os.listdir('./labels/train'))\n",
    "\n",
    "for i in range(5):\n",
    "    first_img_path = \"./images/train/\" + img_files[i]\n",
    "    first_img = cv2.imread(first_img_path)\n",
    "\n",
    "\n",
    "    first_img_anot_path = \"./labels/train/\" + label_files[i]\n",
    "\n",
    "    with open(first_img_anot_path, 'r') as f:\n",
    "        annot = f.readlines()\n",
    "        for cls, xc, yx, w, h in [line.strip().split() for line in annot]:\n",
    "            cv2.rectangle(first_img, \n",
    "                        (int((float(xc) - float(w)/2) * first_img.shape[1]), int((float(yx) - float(h)/2) * first_img.shape[0])),\n",
    "                        (int((float(xc) + float(w)/2) * first_img.shape[1]), int((float(yx) + float(h)/2) * first_img.shape[0])),\n",
    "                        (255, 0, 0), 2)\n",
    "            label = class_names[int(cls)]\n",
    "            cv2.putText(first_img, label,\n",
    "                        (int((float(xc) - float(w)/2) * first_img.shape[1]), int((float(yx) - float(h)/2) * first_img.shape[0]) - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "            \n",
    "    plt.imshow(cv2.cvtColor(first_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, yaml\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"config.yml\") as f:\n",
    "    names = yaml.safe_load(f)[\"names\"]\n",
    "nc = len(names)\n",
    "\n",
    "train_imgs = sorted(glob.glob(\"images/train/*\"))\n",
    "val_imgs   = sorted(glob.glob(\"images/val/*\"))\n",
    "train_labs = sorted(glob.glob(\"labels/train/*.txt\"))\n",
    "val_labs   = sorted(glob.glob(\"labels/val/*.txt\"))\n",
    "print(f\"train: {len(train_imgs)} imgs / {len(train_labs)} labels | val: {len(val_imgs)} / {len(val_labs)}\")\n",
    "\n",
    "empty=0\n",
    "rng=0\n",
    "hist=Counter()\n",
    "\n",
    "for lf in train_labs+val_labs:\n",
    "    lines=[l.strip() for l in open(lf) if l.strip()]\n",
    "    if not lines: \n",
    "        empty+=1 \n",
    "        continue\n",
    "    for ln in lines:\n",
    "        c,xc,yc,w,h=ln.split()[:5]\n",
    "\n",
    "        c=int(float(c))\n",
    "        xc=float(xc)\n",
    "        yc=float(yc)\n",
    "        w=float(w)\n",
    "        h=float(h)\n",
    "\n",
    "        if not (0<=c<nc and 0<=xc<=1 and 0<=yc<=1 and 0<w<=1 and 0<h<=1):\n",
    "            rng+=1\n",
    "        else: \n",
    "            hist[c]+=1\n",
    "\n",
    "print(\"empty label files:\", empty, \"| range/format errors:\", rng)\n",
    "print({names[k]: v for k,v in hist.items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd80ad",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=30\n",
    "BATCH_SIZE=16\n",
    "IMG_SIZE=640\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "model.train(\n",
    "    data=\"config.yml\",\n",
    "    imgsz=IMG_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    batch=BATCH_SIZE,\n",
    "    device=device,\n",
    "    patience=5,\n",
    "    exist_ok=True,\n",
    "    # project=\"runs_thermal\",\n",
    "    # name=\"yolov8s_full\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Evaulation\n",
    "\n",
    "metrics = model.val()\n",
    "metrics = vars(metrics)\n",
    "\n",
    "for k,v in metrics.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4bbe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Inference\n",
    "\n",
<<<<<<< HEAD
    "model = YOLO(\"runs/detect/train/weights/best.pt\") # Load best model from training\n",
    "results = model.predict(source=\"images/train\",\n",
=======
    "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "results = model.predict(source=\"images/val\",\n",
>>>>>>> temp
    "                        imgsz=1280, \n",
    "                        conf=0.5,\n",
    "                        iou=0.35,\n",
    "                        save=True,\n",
    "                        max_det=1000,\n",
    "                        save_txt=True,\n",
    "                        save_conf=True, \n",
    "                        device=device)\n",
    "print(f\"Inference saved to: {results[0].save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea008b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Save Model\n",
    "model.export(format=\"onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
