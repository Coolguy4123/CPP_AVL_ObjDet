{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ENVIRONMENT CHECK ABOUT GPU ---\n",
    "\n",
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(f\"PyTorch version   : {torch.__version__}\")\n",
    "print(f\"CUDA available    : {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version      : {torch.version.cuda}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu = torch.cuda.get_device_properties(0)\n",
    "    vram_gb = gpu.total_memory / 1024**3\n",
    "    print(f\"GPU               : {gpu.name}\")\n",
    "    print(f\"VRAM              : {vram_gb:.1f} GB\")\n",
    "    print(f\"SM count          : {gpu.multi_processor_count}\")\n",
    "\n",
    "    if vram_gb < 20:\n",
    "        print(\"VRAM < 20GB, check batch size settings.\")\n",
    "    else:\n",
    "        print(\"High-VRAM GPU detected\")\n",
    "else:\n",
    "    print(\"No GPU detected\")\n",
    "\n",
    "# Check ultralytics version\n",
    "try:\n",
    "    import ultralytics\n",
    "    print(f\"Ultralytics       : {ultralytics.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Ultralytics not installed — run: pip install ultralytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGS ---\n",
    "# ------------------------------------\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import random\n",
    "import colorsys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "ROOT        = Path(\"..\").resolve()\n",
    "CONFIG_YAML = ROOT / \"config.yml\"\n",
    "RUNS_DIR    = ROOT / \"runs\"\n",
    "VAL_IMG_DIR = ROOT / \"images\" / \"val\"\n",
    "\n",
    "# LOAD CLASS NAMES\n",
    "with open(CONFIG_YAML) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "NAMES = cfg[\"names\"]\n",
    "NC    = cfg[\"nc\"]\n",
    "print(f\"Classes ({NC}): {NAMES}\")\n",
    "\n",
    "# --- TRAINING HYPERPARAMETERS ---\n",
    "# --------------------------------\n",
    "\n",
    "EPOCHS     = 150\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE   = 1024\n",
    "DEVICE     = (\"cuda\" if torch.cuda.is_available()\n",
    "              else \"mps\" if torch.backends.mps.is_available()\n",
    "              else \"cpu\")\n",
    "\n",
    "# FIX 1: batch=64 at imgsz=1024 will OOM even on 32GB VRAM.\n",
    "# At 1024px each image is 2.56x more pixels than 640px.\n",
    "# Safe batch size scales as: batch = desired_batch * (640 / imgsz)^2\n",
    "# RTX 5090 32GB: 64 @ 640px → 25 @ 1024px\n",
    "SAFE_BATCH = max(1, int(BATCH_SIZE * (640 / IMG_SIZE) ** 2))\n",
    "print(f\"Adjusted batch size for imgsz={IMG_SIZE}: {BATCH_SIZE} → {SAFE_BATCH}\")\n",
    "\n",
    "TRAIN_CFG = dict(\n",
    "    model         = \"yolov8s.pt\",\n",
    "    data          = str(CONFIG_YAML),\n",
    "    epochs        = EPOCHS,\n",
    "    imgsz         = IMG_SIZE,\n",
    "    batch         = SAFE_BATCH,       # FIX 1: scaled for 1024px\n",
    "    workers       = 8,\n",
    "    device        = DEVICE,\n",
    "    project       = str(RUNS_DIR),\n",
    "    name          = \"yolov8s_thermal\",\n",
    "    exist_ok      = False,            # set True to resume into same folder\n",
    "    # ── Optimiser ──\n",
    "    optimizer     = \"AdamW\",\n",
    "    lr0           = 0.001,\n",
    "    lrf           = 0.01,\n",
    "    momentum      = 0.937,\n",
    "    weight_decay  = 0.0005,\n",
    "    warmup_epochs = 3,\n",
    "    # ── Augmentation ──\n",
    "    # Custom aug pipeline already exists, keep built-in conservative\n",
    "    mosaic        = 0.5,\n",
    "    mixup         = 0.1,\n",
    "    copy_paste    = 0.1,\n",
    "    degrees       = 5.0,\n",
    "    translate     = 0.1,\n",
    "    scale         = 0.5,\n",
    "    fliplr        = 0.5,\n",
    "    flipud        = 0.0,              # thermal images are always upright\n",
    "    hsv_h         = 0.0,              # thermal is greyscale — no hue shift\n",
    "    hsv_s         = 0.0,              # no saturation shift\n",
    "    hsv_v         = 0.3,              # brightness variation only\n",
    "    # ── Loss weights ──\n",
    "    box           = 7.5,\n",
    "    cls           = 0.5,\n",
    "    dfl           = 1.5,\n",
    "    # ── Precision ──\n",
    "    amp           = True,             # BF16 on RTX 5090 Blackwell arch\n",
    "    # ── Early stopping ──\n",
    "    patience      = 30,\n",
    "    # ── Saving ──\n",
    "    save          = True,\n",
    "    save_period   = 10,\n",
    "    val           = True,\n",
    "    plots         = True,\n",
    "    verbose       = True,\n",
    ")\n",
    "\n",
    "print(\"\\nTraining config:\")\n",
    "for k, v in TRAIN_CFG.items():\n",
    "    print(f\"  {k:<18}: {v}\")\n",
    "\n",
    "model = YOLO(TRAIN_CFG[\"model\"])\n",
    "\n",
    "results = model.train(**{k: v for k, v in TRAIN_CFG.items() if k != \"model\"})\n",
    "\n",
    "# Path to best weights — used in all cells below\n",
    "BEST_WEIGHTS = Path(results.save_dir) / \"weights\" / \"best.pt\"\n",
    "print(f\"\\n✓ Training complete\")\n",
    "print(f\"  Best weights : {BEST_WEIGHTS}\")\n",
    "print(f\"  Results dir  : {results.save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and mAP curves from the CSV YOLO writes during training.\n",
    "# Run this after training completes or while it's running (partial curves).\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Auto-find latest run if BEST_WEIGHTS not set (e.g. re-running notebook)\n",
    "if \"BEST_WEIGHTS\" not in dir() or not Path(BEST_WEIGHTS).exists():\n",
    "    run_dirs = sorted(Path(RUNS_DIR).glob(\"yolov8s_thermal*\"), key=lambda p: p.stat().st_mtime)\n",
    "    if not run_dirs:\n",
    "        raise FileNotFoundError(f\"No run directories found in {RUNS_DIR}\")\n",
    "    latest_run   = run_dirs[-1]\n",
    "    BEST_WEIGHTS = latest_run / \"weights\" / \"best.pt\"\n",
    "    print(f\"Using latest run: {latest_run}\")\n",
    "else:\n",
    "    latest_run = Path(BEST_WEIGHTS).parent.parent\n",
    "\n",
    "results_csv = latest_run / \"results.csv\"\n",
    "if not results_csv.exists():\n",
    "    print(\"results.csv not found — training may not have started yet\")\n",
    "else:\n",
    "    df = pd.read_csv(results_csv)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.patch.set_facecolor(\"#0e0e0e\")\n",
    "    fig.suptitle(\"YOLOv8s Training Curves\", color=\"white\", fontsize=15)\n",
    "\n",
    "    plot_pairs = [\n",
    "        (\"train/box_loss\",       \"val/box_loss\",           \"Box Loss\"),\n",
    "        (\"train/cls_loss\",       \"val/cls_loss\",           \"Class Loss\"),\n",
    "        (\"train/dfl_loss\",       \"val/dfl_loss\",           \"DFL Loss\"),\n",
    "        (\"metrics/mAP50(B)\",     None,                     \"mAP@0.5\"),\n",
    "        (\"metrics/mAP50-95(B)\", None,                      \"mAP@0.5:0.95\"),\n",
    "        (\"metrics/precision(B)\",\"metrics/recall(B)\",       \"Precision / Recall\"),\n",
    "    ]\n",
    "\n",
    "    for ax, (col1, col2, title) in zip(axes.flat, plot_pairs):\n",
    "        ax.set_facecolor(\"#1a1a1a\")\n",
    "        ax.tick_params(colors=\"white\")\n",
    "        ax.set_title(title, color=\"white\", fontsize=11)\n",
    "        ax.set_xlabel(\"Epoch\", color=\"grey\")\n",
    "        if col1 in df.columns:\n",
    "            label1 = \"Train\" if col2 else col1.split(\"/\")[-1]\n",
    "            ax.plot(df[\"epoch\"], df[col1], label=label1, color=\"steelblue\", linewidth=1.8)\n",
    "        if col2 and col2 in df.columns:\n",
    "            label2 = \"Val\" if \"loss\" in col2 else col2.split(\"/\")[-1]\n",
    "            ax.plot(df[\"epoch\"], df[col2], label=label2, color=\"coral\", linewidth=1.8)\n",
    "        ax.legend(facecolor=\"#2a2a2a\", labelcolor=\"white\", fontsize=9)\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor(\"#333\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(f\"\\nFinal epoch metrics:\")\n",
    "    metric_cols = [c for c in df.columns if \"metric\" in c.lower() or \"map\" in c.lower()]\n",
    "    print(df[metric_cols].tail(1).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8308f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VALIDATION SET EVALUATION ---\n",
    "\n",
    "model = YOLO(str(BEST_WEIGHTS))\n",
    "\n",
    "\n",
    "metrics = model.val(\n",
    "    data    = str(CONFIG_YAML),\n",
    "    imgsz   = IMG_SIZE,   \n",
    "    batch   = SAFE_BATCH,\n",
    "    device  = DEVICE,\n",
    "    conf    = 0.15,\n",
    "    iou     = 0.40,\n",
    "    plots   = True,\n",
    "    verbose = True,\n",
    ")\n",
    "\n",
    "# --- Per-class AP table ---\n",
    "print(\"\\n\" + \"─\" * 62)\n",
    "print(f\"{'Class':<16} {'AP@0.5':>9} {'AP@0.5:0.95':>12} {'Precision':>10} {'Recall':>8}\")\n",
    "print(\"─\" * 62)\n",
    "\n",
    "ap50   = metrics.box.ap50\n",
    "ap5095 = metrics.box.ap\n",
    "prec   = metrics.box.p\n",
    "rec    = metrics.box.r\n",
    "\n",
    "for i, name in enumerate(NAMES):\n",
    "    p  = prec[i]   if i < len(prec)   else float('nan')\n",
    "    r  = rec[i]    if i < len(rec)    else float('nan')\n",
    "    a5 = ap50[i]   if i < len(ap50)   else float('nan')\n",
    "    a9 = ap5095[i] if i < len(ap5095) else float('nan')\n",
    "    print(f\"{name:<16} {a5:>9.3f} {a9:>12.3f} {p:>10.3f} {r:>8.3f}\")\n",
    "\n",
    "print(\"─\" * 62)\n",
    "print(f\"{'mAP':<16} {metrics.box.map50:>9.3f} {metrics.box.map:>12.3f}\")\n",
    "print(\"─\" * 62)\n",
    "\n",
    "#  --- Flag classes with low recall ---\n",
    "print(\"\\n**** Classes with recall < 0.5 (missed detections):\")\n",
    "low_recall = [(NAMES[i], rec[i]) for i in range(len(NAMES)) if i < len(rec) and rec[i] < 0.5]\n",
    "if low_recall:\n",
    "    for name, r in low_recall:\n",
    "        print(f\"  {name:<16} recall = {r:.3f}\")\n",
    "else:\n",
    "    print(\"  None — all classes above 0.5 recall ✓\")\n",
    "\n",
    "\n",
    "# Display the confusion matrix and per-class PR curves saved by YOLO during val.\n",
    "val_dir = Path(metrics.save_dir)\n",
    "\n",
    "plot_files = {\n",
    "    \"Confusion Matrix\"       : val_dir / \"confusion_matrix.png\",\n",
    "    \"Confusion Matrix (norm)\": val_dir / \"confusion_matrix_normalized.png\",\n",
    "    \"PR Curve\"               : val_dir / \"PR_curve.png\",\n",
    "    \"F1 Curve\"               : val_dir / \"F1_curve.png\",\n",
    "}\n",
    "\n",
    "available = {k: v for k, v in plot_files.items() if v.exists()}\n",
    "if not available:\n",
    "    print(\"No plot files found — ensure plots=True was set during val\")\n",
    "else:\n",
    "    fig, axes = plt.subplots(1, len(available), figsize=(8 * len(available), 7))\n",
    "    if len(available) == 1:\n",
    "        axes = [axes]\n",
    "    fig.patch.set_facecolor(\"#0e0e0e\")\n",
    "\n",
    "    for ax, (title, path) in zip(axes, available.items()):\n",
    "        img = cv2.imread(str(path))\n",
    "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax.set_title(title, color=\"white\", fontsize=12)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a761051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INFERENCE ON SPECIFIC CLASS --- \n",
    "TARGET_CLASS = \"large_vehicle\"   # change to any class name\n",
    "NUM_SAMPLES  = 4\n",
    "CONF_THRESH  = 0.15\n",
    "IOU_THRESH   = 0.40\n",
    "\n",
    "target_idx = NAMES.index(TARGET_CLASS) if TARGET_CLASS in NAMES else None\n",
    "if target_idx is None:\n",
    "    raise ValueError(f\"Class '{TARGET_CLASS}' not in {NAMES}\")\n",
    "\n",
    "target_imgs = []\n",
    "for txt in (ROOT / \"labels\" / \"val\").glob(\"*.txt\"):\n",
    "    for ln in txt.read_text().splitlines():\n",
    "        if ln.strip() and int(ln.split()[0]) == target_idx:\n",
    "            img_path = VAL_IMG_DIR / (txt.stem + \".jpg\")\n",
    "            if img_path.exists():\n",
    "                target_imgs.append(img_path)\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(target_imgs)} val images containing '{TARGET_CLASS}'\")\n",
    "if not target_imgs:\n",
    "    print(\"No images found — check TARGET_CLASS name and val label directory\")\n",
    "else:\n",
    "    samples = random.sample(target_imgs, min(NUM_SAMPLES, len(target_imgs)))\n",
    "    results = model.predict(\n",
    "        source  = [str(p) for p in samples],\n",
    "        imgsz   = IMG_SIZE,\n",
    "        conf    = CONF_THRESH,\n",
    "        iou     = IOU_THRESH,\n",
    "        device  = DEVICE,\n",
    "        verbose = False,\n",
    "    )\n",
    "\n",
    "    for img_path, result in zip(samples, results):\n",
    "        bgr = cv2.imread(str(img_path))\n",
    "        if bgr is None:\n",
    "            continue\n",
    "        rgb      = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "        lbl_path = ROOT / \"labels\" / \"val\" / (img_path.stem + \".txt\")\n",
    "        gt_img   = draw_gt_boxes(rgb, lbl_path, NAMES)\n",
    "        pred_img = draw_pred_boxes(rgb, result, NAMES)\n",
    "\n",
    "        gt_count   = sum(1 for ln in lbl_path.read_text().splitlines()\n",
    "                         if ln.strip() and int(ln.split()[0]) == target_idx)\n",
    "        pred_count = sum(1 for b in (result.boxes or [])\n",
    "                         if int(b.cls[0]) == target_idx)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "        fig.patch.set_facecolor(\"#0e0e0e\")\n",
    "        fig.suptitle(f\"Class filter: {TARGET_CLASS}  |  {img_path.name}\",\n",
    "                     color=\"#aaa\", fontsize=9)\n",
    "        axes[0].imshow(gt_img)\n",
    "        axes[0].set_title(f\"Ground Truth  ({gt_count} {TARGET_CLASS})\",\n",
    "                          color=\"white\", fontsize=12)\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(pred_img)\n",
    "        axes[1].set_title(f\"Prediction  ({pred_count} {TARGET_CLASS} detected)\",\n",
    "                          color=\"white\", fontsize=12)\n",
    "        axes[1].axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INFERENCE AND SIDE BY SIDE COMPARISON ---\n",
    "\n",
    "NUM_SAMPLES  = 6\n",
    "CONF_THRESH  = 0.15\n",
    "IOU_THRESH   = 0.40\n",
    "SEED         = 42\n",
    "\n",
    "IMG_EXTS    = (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "VAL_LBL_DIR = ROOT / \"labels\" / \"val\"\n",
    "\n",
    "model = YOLO(str(BEST_WEIGHTS))\n",
    "\n",
    "\n",
    "def class_color(cls_id: int):\n",
    "    \"\"\"Consistent HSV-derived colour per class index.\"\"\"\n",
    "    h = (cls_id * 37) % 360\n",
    "    r, g, b = colorsys.hsv_to_rgb(h / 360.0, 0.9, 0.95)\n",
    "    return (int(r*255), int(g*255), int(b*255))\n",
    "\n",
    "\n",
    "def draw_gt_boxes(img_rgb: np.ndarray, label_path: Path, names: list) -> np.ndarray:\n",
    "    \"\"\"Draw ground truth YOLO boxes onto an RGB image.\"\"\"\n",
    "    h, w   = img_rgb.shape[:2]\n",
    "    canvas = img_rgb.copy()\n",
    "    if not label_path.exists():\n",
    "        return canvas\n",
    "    for ln in label_path.read_text().splitlines():\n",
    "        parts = ln.strip().split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        cls = int(parts[0])\n",
    "        cx, cy, bw, bh = map(float, parts[1:5])\n",
    "        x1 = max(0, int((cx - bw/2) * w))\n",
    "        y1 = max(0, int((cy - bh/2) * h))\n",
    "        x2 = min(w, int((cx + bw/2) * w))\n",
    "        y2 = min(h, int((cy + bh/2) * h))\n",
    "        color = class_color(cls)\n",
    "        cv2.rectangle(canvas, (x1, y1), (x2, y2), color, 2, cv2.LINE_AA)\n",
    "        label = names[cls] if cls < len(names) else str(cls)\n",
    "        _draw_label(canvas, label, x1, y1, color)\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def draw_pred_boxes(img_rgb: np.ndarray, result, names: list) -> np.ndarray:\n",
    "    \"\"\"Draw YOLO prediction boxes onto an RGB image.\"\"\"\n",
    "    canvas = img_rgb.copy()\n",
    "    boxes  = result.boxes\n",
    "    if boxes is None or len(boxes) == 0:\n",
    "        return canvas\n",
    "    for box in boxes:\n",
    "        cls   = int(box.cls[0])\n",
    "        conf  = float(box.conf[0])\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        color = class_color(cls)\n",
    "        cv2.rectangle(canvas, (x1, y1), (x2, y2), color, 2, cv2.LINE_AA)\n",
    "        label = f\"{names[cls] if cls < len(names) else cls} {conf:.2f}\"\n",
    "        _draw_label(canvas, label, x1, y1, color)\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def _draw_label(img: np.ndarray, text: str, x: int, y: int, color: tuple):\n",
    "    \"\"\"Draw filled label rectangle above a bounding box.\"\"\"\n",
    "    font        = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale       = 0.48\n",
    "    thickness   = 1\n",
    "    (tw, th), _ = cv2.getTextSize(text, font, scale, thickness)\n",
    "    pad = 4\n",
    "    ly1 = max(0, y - th - pad * 2)\n",
    "    ly2 = y\n",
    "    lx2 = min(img.shape[1], x + tw + pad)\n",
    "    cv2.rectangle(img, (x, ly1), (lx2, ly2), color, -1)\n",
    "    lum = (0.299*color[0] + 0.587*color[1] + 0.114*color[2]) / 255\n",
    "    tc  = (0, 0, 0) if lum > 0.55 else (255, 255, 255)\n",
    "    cv2.putText(img, text, (x + pad, ly2 - pad), font, scale, tc, thickness, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "all_imgs = sorted([p for p in VAL_IMG_DIR.iterdir() if p.suffix.lower() in IMG_EXTS])\n",
    "if not all_imgs:\n",
    "    raise FileNotFoundError(f\"No images found in {VAL_IMG_DIR}\")\n",
    "\n",
    "if SEED is not None:\n",
    "    random.seed(SEED)\n",
    "samples = random.sample(all_imgs, min(NUM_SAMPLES, len(all_imgs)))\n",
    "\n",
    "results = model.predict(\n",
    "    source  = [str(p) for p in samples],\n",
    "    imgsz   = IMG_SIZE,   \n",
    "    conf    = CONF_THRESH,\n",
    "    iou     = IOU_THRESH,\n",
    "    device  = DEVICE,\n",
    "    verbose = False,\n",
    ")\n",
    "\n",
    "for img_path, result in zip(samples, results):\n",
    "    bgr = cv2.imread(str(img_path))\n",
    "    if bgr is None:\n",
    "        continue\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    lbl_path = VAL_LBL_DIR / (img_path.stem + \".txt\")\n",
    "    gt_img   = draw_gt_boxes(rgb,  lbl_path, NAMES)\n",
    "    pred_img = draw_pred_boxes(rgb, result,  NAMES)\n",
    "\n",
    "    gt_count   = len(lbl_path.read_text().splitlines()) if lbl_path.exists() else 0\n",
    "    pred_count = len(result.boxes) if result.boxes is not None else 0\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    fig.patch.set_facecolor(\"#0e0e0e\")\n",
    "    fig.suptitle(img_path.name, color=\"#aaa\", fontsize=9)\n",
    "\n",
    "    axes[0].imshow(gt_img)\n",
    "    axes[0].set_title(f\"Ground Truth  ({gt_count} boxes)\",\n",
    "                      color=\"white\", fontsize=12, pad=8)\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(pred_img)\n",
    "    axes[1].set_title(f\"Prediction  ({pred_count} boxes)  conf≥{CONF_THRESH}\",\n",
    "                      color=\"white\", fontsize=12, pad=8)\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(f\"  GT: {gt_count} boxes  |  Pred: {pred_count} boxes  |  {img_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- EXPORT MODEL ---\n",
    "\n",
    "model = YOLO(str(BEST_WEIGHTS))\n",
    "\n",
    "# --- ONNX ---\n",
    "# exported = model.export(\n",
    "#     format   = \"onnx\",\n",
    "#     imgsz    = IMG_SIZE,\n",
    "#     dynamic  = False,\n",
    "#     simplify = True,\n",
    "#     device   = DEVICE,\n",
    "# )\n",
    "\n",
    "# -- TensorRT --\n",
    "exported = model.export(\n",
    "    format    = \"engine\",\n",
    "    imgsz     = IMG_SIZE,\n",
    "    half      = True,\n",
    "    device    = DEVICE,\n",
    "    workspace = 8,\n",
    "    verbose   = False,\n",
    ")\n",
    "\n",
    "print(f\"\\n Model exported to: {exported}\")\n",
    "# print(\"  Load with: model = YOLO('path/to/best.engine')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
