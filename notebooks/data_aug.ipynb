{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e59919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FOR DATA AUGMENTATION ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc4bf818",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run ./data_process.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252adf17",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define folders for augmentation dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# ~~~~~~~~~~ Config ~~~~~~~~~~\n",
    "IMG_DIR   = r\"C:\\Users\\youch\\CPP_AVL_ObjDet\\images\\train\"\n",
    "LABEL_DIR = r\"C:\\Users\\youch\\CPP_AVL_ObjDet\\labels\\train\"\n",
    "ROOT = r\"C:\\Users\\youch\\CPP_AVL_ObjDet\"\n",
    "OUT_IMG = os.path.join(ROOT, \"images\", \"train_augmented\")\n",
    "OUT_LBL = os.path.join(ROOT, \"labels\", \"train_augmented\")\n",
    "\n",
    "MIN_BOX_AREA   = 0.001    # discard boxes smaller than 0.1% of image after transform\n",
    "\n",
    "os.makedirs(OUT_IMG, exist_ok=True)\n",
    "os.makedirs(OUT_LBL, exist_ok=True)         \n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~ Function to load labels ~~~~~~~~~~~~~~~~~~~~~~\n",
    "def load_labels(label_path):\n",
    "    labels = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                class_id = int(parts[0])\n",
    "                x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                labels.append((class_id, x_center, y_center, width, height))\n",
    "    return labels\n",
    "\n",
    "# ~~~~~~~~~~~~ Save the labels into the output folder ~~~~~~~~~~~~\n",
    "def save_labels(labels, out_path):\n",
    "    with open(out_path, \"w\") as f:\n",
    "        for b in labels:\n",
    "            f.write(f\"{b[0]} {b[1]:.6f} {b[2]:.6f} {b[3]:.6f} {b[4]:.6f}\\n\")\n",
    "\n",
    "# ~~~~~~~~~~~~ Clipping ~~~~~~~~~~~~\n",
    "def clip_labels(cx, cy, w, h):\n",
    "    x1 = max(0.0, cx - w / 2)\n",
    "    y1 = max(0.0, cy - h / 2)\n",
    "    x2 = min(1.0, cx + w / 2)\n",
    "    y2 = min(1.0, cy + h / 2)\n",
    "    new_w = x2 - x1\n",
    "    new_h = y2 - y1\n",
    "    new_cx = x1 + new_w / 2\n",
    "    new_cy = y1 + new_h / 2\n",
    "    return new_cx, new_cy, new_w, new_h\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~ Check if it is a valid box after transformation ~~~~~~~~~~~\n",
    "def is_valid_box(cx, cy, w, h):\n",
    "    return w > 0 and h > 0 and w * h >= MIN_BOX_AREA\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~ Augmentation #1: Cropping ~~~~~~~~~~~~\n",
    "def random_crop(img, boxes, target_classes = {1, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14}, crop_ratio_range=(0.6, 0.9)):\n",
    "    has_target = any(b[0] in target_classes for b in boxes)\n",
    "    if not has_target:\n",
    "        return None, None\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    ratio = random.uniform(*crop_ratio_range)\n",
    "    \n",
    "    crop_w = int(w * ratio)\n",
    "    crop_h = int(h * ratio)\n",
    "    x_off = random.randint(0, w - crop_w)\n",
    "    y_off = random.randint(0, h - crop_h)\n",
    "    \n",
    "    cropped = img[y_off:y_off+crop_h, x_off:x_off+crop_w]\n",
    "    cropped = cv2.resize(cropped, (w, h))  # Resize back to original size\n",
    "    \n",
    "    new_boxes = []\n",
    "    \n",
    "    for cls, cx, cy, bw, bh in boxes:\n",
    "        # Convert to pixel coordinates\n",
    "        px1 = (cx - bw / 2) * w\n",
    "        py1 = (cy - bh / 2) * h\n",
    "        px2 = (cx + bw / 2) * w\n",
    "        py2 = (cy + bh / 2) * h\n",
    "        \n",
    "        # Clip to crop\n",
    "        cx1 = max(px1, x_off)\n",
    "        cy1 = max(py1, y_off)\n",
    "        cx2 = min(px2, x_off + crop_w)\n",
    "        cy2 = min(py2, y_off + crop_h)\n",
    "        \n",
    "        if cx2 <= cx1 or cy2 <= cy1:\n",
    "            continue  # Box is completely outside crop\n",
    "        \n",
    "        \n",
    "        visible_area = (cx2 - cx1) * (cy2 - cy1)\n",
    "        original_area = (px2 - px1) * (py2 - py1)\n",
    "        if original_area > 0 and visible_area / original_area < 0.5:\n",
    "            continue  # Less than 50% visible, discard\n",
    "        \n",
    "        \n",
    "        # Normalize back to [0,1]\n",
    "        new_cx = (cx1 + cx2) / 2 / crop_w\n",
    "        new_cy = (cy1 + cy2) / 2 / crop_h\n",
    "        new_bw = (cx2 - cx1) / crop_w\n",
    "        new_bh = (cy2 - cy1) / crop_h\n",
    "        \n",
    "        if is_valid_box(new_cx, new_cy, new_bw, new_bh):\n",
    "            new_boxes.append([cls, new_cx, new_cy, new_bw, new_bh])\n",
    "            \n",
    "    return cropped, new_boxes\n",
    "\n",
    "# ~~~~~~~~~~~ Augmentation #2: Horizontal Flip ~~~~~~~~~~~~\n",
    "def horizontal_flip(img, boxes, target_classes={1, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14}):\n",
    "    has_target = any(b[0] in target_classes for b in boxes)\n",
    "    if not has_target:\n",
    "        return None, None\n",
    "    \n",
    "    flipped = cv2.flip(img, 1)\n",
    "    new_boxes = []\n",
    "    for cls, cx, cy, bw, bh in boxes:\n",
    "        new_boxes.append([cls, 1.0 - cx, cy, bw, bh])  # mirror cx\n",
    "    \n",
    "    return flipped, new_boxes\n",
    "\n",
    "# ~~~~~~~~~~~ Augmentation #3: Cropped Person ~~~~~~~~~~~~\n",
    "def cropped_person(img, boxes):\n",
    "    h, w = img.shape[:2]\n",
    "    person_boxes = [b for b in boxes if b[0] == 0]  # class 0 = person\n",
    "    if not person_boxes:\n",
    "        return None, None\n",
    "    \n",
    "    #  Pick a random person to crop around\n",
    "    target = random.choice(person_boxes)\n",
    "    cls, cx, cy, bw, bh = target\n",
    "    \n",
    "    # Convert to pixel coords\n",
    "    px1 = int((cx - bw/2) * w)\n",
    "    py1 = int((cy - bh/2) * h)\n",
    "    px2 = int((cx + bw/2) * w)\n",
    "    py2 = int((cy + bh/2) * h)\n",
    "    person_h = py2 - py1\n",
    "    \n",
    "    # Randomly crop top half or bottom half\n",
    "    if random.random() < 0.5:\n",
    "        # Keep top half (head to waist)\n",
    "        crop_y2 = py1 + int(person_h * random.uniform(0.4, 0.6))\n",
    "        crop_y1 = 0\n",
    "    else:\n",
    "        # Keep bottom half (waist to feet)\n",
    "        crop_y1 = py1 + int(person_h * random.uniform(0.4, 0.6))\n",
    "        crop_y2 = h\n",
    "    \n",
    "    crop_y1 = max(0, crop_y1)\n",
    "    crop_y2 = min(h, crop_y2)\n",
    "    \n",
    "    if crop_y2 - crop_y1 < 50:\n",
    "        return None, None\n",
    "    \n",
    "    cropped = img[crop_y1:crop_y2, 0:w]\n",
    "    new_h = crop_y2 - crop_y1\n",
    "    cropped = cv2.resize(cropped, (w, h))  # resize back to original dims\n",
    "    \n",
    "    new_boxes = []\n",
    "    for cls, cx, cy, bw, bh in boxes:\n",
    "        px1 = (cx - bw/2) * w;  py1 = (cy - bh/2) * h\n",
    "        px2 = (cx + bw/2) * w;  py2 = (cy + bh/2) * h\n",
    "        \n",
    "        # Intersect with crop\n",
    "        iy1 = max(py1, crop_y1);  iy2 = min(py2, crop_y2)\n",
    "        ix1 = max(px1, 0);        ix2 = min(px2, w)\n",
    "        \n",
    "        if iy2 <= iy1 or ix2 <= ix1:\n",
    "            continue\n",
    "        \n",
    "        vis = (iy2 - iy1) * (ix2 - ix1)\n",
    "        orig = (py2 - py1) * (px2 - px1)\n",
    "        \n",
    "        # Lower visibility threshold for person (20%), normal for others (50%)\n",
    "        min_vis = 0.2 if cls == 0 else 0.5\n",
    "        if orig > 0 and vis / orig < min_vis:\n",
    "            continue\n",
    "        \n",
    "        # Normalize relative to crop, then scale back since we resized to original\n",
    "        new_cx = (ix1 + ix2) / 2 / w\n",
    "        new_cy = ((iy1 + iy2) / 2 - crop_y1) / new_h\n",
    "        new_bw = (ix2 - ix1) / w\n",
    "        new_bh = (iy2 - iy1) / new_h\n",
    "        \n",
    "        if is_valid_box(new_cx, new_cy, new_bw, new_bh):\n",
    "            new_boxes.append([cls, new_cx, new_cy, new_bw, new_bh])\n",
    "    \n",
    "    return cropped, new_boxes\n",
    "\n",
    "\n",
    "augmentations = {'crop': random_crop,\n",
    "                 'flip': horizontal_flip,\n",
    "                 'crop person': cropped_person}\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~ Main loop to process dataset ~~~~~~~~~~~~\n",
    "\n",
    "img_paths = list(Path(IMG_DIR).glob(\"*.jpg\"))\n",
    "\n",
    "for img_path in img_paths:\n",
    "    label_path = Path(LABEL_DIR) / (img_path.stem + \".txt\")\n",
    "    if not label_path.exists():\n",
    "        continue\n",
    "    \n",
    "    labels = load_labels(str(label_path))\n",
    "        \n",
    "    if not labels:\n",
    "        continue  # Skip images without target classes\n",
    "    \n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    for aug_name, aug_func in augmentations.items():\n",
    "        aug_img, aug_labels = aug_func(img.copy(), [list(b) for b in labels])\n",
    "        \n",
    "        if aug_img is None or not aug_labels:\n",
    "            continue  # this augmentation didn't apply to this image\n",
    "        \n",
    "        out_stem = f\"{img_path.stem}_{aug_name}\"\n",
    "        cv2.imwrite(str(Path(OUT_IMG) / f\"{out_stem}.jpg\"), aug_img)\n",
    "        save_labels(aug_labels, str(Path(OUT_LBL) / f\"{out_stem}.txt\"))\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff03fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Augmentation complete: 17155 augmented images created in C:\\Users\\youch\\CPP_AVL_ObjDet\\images\\train_augmented\n",
      "✓ Augmentation complete: 17155 augmented label files created in C:\\Users\\youch\\CPP_AVL_ObjDet\\labels\\train_augmented\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~ Statistics ad Visualizations ~~~~~~~~~~~~\n",
    "total_augmented = len(list(Path(OUT_IMG).glob(\"*.jpg\")))\n",
    "print(f\"✓ Augmentation complete: {total_augmented} augmented images created in {OUT_IMG}\")\n",
    "total_augmented_labels = len(list(Path(OUT_LBL).glob(\"*.txt\")))\n",
    "print(f\"✓ Augmentation complete: {total_augmented_labels} augmented label files created in {OUT_LBL}\")\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# ~~~~~~~~~~~ Config ~~~~~~~~~~~~\n",
    "ROOT       = r\"C:\\Users\\youch\\CPP_AVL_ObjDet\"\n",
    "LABEL_DIRS = {\n",
    "    \"train\":           ROOT + r\"\\labels\\train\",\n",
    "    \"train_augmented\": ROOT + r\"\\labels\\train_augmented\",\n",
    "}\n",
    "YAML_PATH  = ROOT + r\"\\config.yml\"\n",
    "\n",
    "with open(YAML_PATH) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "names = cfg[\"names\"]  # ['person', 'bike', 'car', ...]\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~ Load all labels from a folder ~~~~~~~~~~~~\n",
    "def load_all_labels(label_dir):\n",
    "    \"\"\"Returns list of (class_id, cx, cy, w, h) for all boxes in folder\"\"\"\n",
    "    all_boxes = []\n",
    "    for txt in Path(label_dir).glob(\"*.txt\"):\n",
    "        with open(txt) as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 5:\n",
    "                    cls = int(parts[0])\n",
    "                    cx, cy, w, h = map(float, parts[1:])\n",
    "                    all_boxes.append((cls, cx, cy, w, h))\n",
    "    return all_boxes\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~ Gather stats ~~~~~~~~~~~~\n",
    "stats = {}\n",
    "for split, ldir in LABEL_DIRS.items():\n",
    "    boxes = load_all_labels(ldir)\n",
    "    stats[split] = {\n",
    "        \"boxes\":       boxes,\n",
    "        \"num_images\":  len(list(Path(ldir).glob(\"*.txt\"))),\n",
    "        \"num_boxes\":   len(boxes),\n",
    "        \"class_count\": Counter(b[0] for b in boxes),\n",
    "        \"widths\":      [b[3] for b in boxes],\n",
    "        \"heights\":     [b[4] for b in boxes],\n",
    "        \"areas\":       [b[3] * b[4] for b in boxes],\n",
    "    }\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~ Plot ~~~~~~~~~~~~\n",
    "fig = plt.figure(figsize=(18, 14))\n",
    "fig.suptitle(\"Dataset Statistics: train vs train_augmented\", fontsize=15, fontweight=\"bold\")\n",
    "gs = gridspec.GridSpec(3, 3, figure=fig, hspace=0.45, wspace=0.35)\n",
    "\n",
    "colors = {\"train\": \"#4C72B0\", \"train_augmented\": \"#DD8452\"}\n",
    "\n",
    "# ── 1. Image & box count ──────────────────────────────────────────\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "splits   = list(stats.keys())\n",
    "n_images = [stats[s][\"num_images\"] for s in splits]\n",
    "n_boxes  = [stats[s][\"num_boxes\"]  for s in splits]\n",
    "x = np.arange(len(splits))\n",
    "bars = ax1.bar(x - 0.2, n_images, 0.35, label=\"Images\", color=[colors[s] for s in splits], alpha=0.85)\n",
    "bars2 = ax1.bar(x + 0.2, n_boxes,  0.35, label=\"Boxes\",  color=[colors[s] for s in splits], alpha=0.5)\n",
    "ax1.set_xticks(x); ax1.set_xticklabels(splits, rotation=10)\n",
    "ax1.set_title(\"Image & Box Count\")\n",
    "ax1.legend(fontsize=8)\n",
    "for bar in list(bars) + list(bars2):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
    "             str(int(bar.get_height())), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "\n",
    "# ── 2. Class distribution per split ──────────────────────────────\n",
    "ax2 = fig.add_subplot(gs[0, 1:])\n",
    "all_class_ids = sorted(set(\n",
    "    cid for s in stats for cid in stats[s][\"class_count\"]\n",
    "))\n",
    "class_labels = [names[i] if i < len(names) else str(i) for i in all_class_ids]\n",
    "x = np.arange(len(all_class_ids))\n",
    "width = 0.35\n",
    "for i, (split, color) in enumerate(colors.items()):\n",
    "    counts = [stats[split][\"class_count\"].get(cid, 0) for cid in all_class_ids]\n",
    "    offset = (i - 0.5) * width\n",
    "    bars = ax2.bar(x + offset, counts, width, label=split, color=color, alpha=0.85)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(class_labels, rotation=35, ha='right', fontsize=8)\n",
    "ax2.set_title(\"Class Distribution\")\n",
    "ax2.legend(fontsize=8)\n",
    "\n",
    "\n",
    "# ── 3. Box width distribution ─────────────────────────────────────\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "for split, color in colors.items():\n",
    "    ax3.hist(stats[split][\"widths\"], bins=50, color=color,\n",
    "             alpha=0.6, label=split, density=True)\n",
    "ax3.set_title(\"Box Width Distribution (normalized)\")\n",
    "ax3.set_xlabel(\"Width (0–1)\"); ax3.legend(fontsize=8)\n",
    "\n",
    "\n",
    "# ── 4. Box height distribution ────────────────────────────────────\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "for split, color in colors.items():\n",
    "    ax4.hist(stats[split][\"heights\"], bins=50, color=color,\n",
    "             alpha=0.6, label=split, density=True)\n",
    "ax4.set_title(\"Box Height Distribution (normalized)\")\n",
    "ax4.set_xlabel(\"Height (0–1)\"); ax4.legend(fontsize=8)\n",
    "\n",
    "\n",
    "# ── 5. Box area distribution ──────────────────────────────────────\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "for split, color in colors.items():\n",
    "    ax5.hist(stats[split][\"areas\"], bins=50, color=color,\n",
    "             alpha=0.6, label=split, density=True)\n",
    "ax5.set_title(\"Box Area Distribution (normalized)\")\n",
    "ax5.set_xlabel(\"Area (w×h)\"); ax5.legend(fontsize=8)\n",
    "\n",
    "\n",
    "# ── 6. Box center scatter (cx, cy) ───────────────────────────────\n",
    "for i, (split, color) in enumerate(colors.items()):\n",
    "    ax = fig.add_subplot(gs[2, i])\n",
    "    cxs = [b[1] for b in stats[split][\"boxes\"]]\n",
    "    cys = [b[2] for b in stats[split][\"boxes\"]]\n",
    "    ax.scatter(cxs, cys, s=1, alpha=0.3, color=color)\n",
    "    ax.set_xlim(0, 1); ax.set_ylim(0, 1)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(f\"Box Centers: {split}\")\n",
    "    ax.set_xlabel(\"cx\"); ax.set_ylabel(\"cy\")\n",
    "\n",
    "\n",
    "# ── 7. Summary table ─────────────────────────────────────────────\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "ax7.axis(\"off\")\n",
    "table_data = []\n",
    "for split in splits:\n",
    "    s = stats[split]\n",
    "    avg_per_img = s[\"num_boxes\"] / s[\"num_images\"] if s[\"num_images\"] > 0 else 0\n",
    "    table_data.append([\n",
    "        split,\n",
    "        str(s[\"num_images\"]),\n",
    "        str(s[\"num_boxes\"]),\n",
    "        f\"{avg_per_img:.1f}\",\n",
    "    ])\n",
    "table = ax7.table(\n",
    "    cellText=table_data,\n",
    "    colLabels=[\"Split\", \"Images\", \"Boxes\", \"Avg boxes/img\"],\n",
    "    loc=\"center\", cellLoc=\"center\"\n",
    ")\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1.2, 1.8)\n",
    "ax7.set_title(\"Summary\", fontweight=\"bold\")\n",
    "\n",
    "plt.savefig(str(Path(ROOT) / \"augmentation_stats.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Stats saved to {ROOT}\\\\augmentation_stats.png\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678876a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
